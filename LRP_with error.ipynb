{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten , Dropout , BatchNormalization, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import Callback, ModelCheckpoint, CSVLogger\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3816 images belonging to 2 classes.\n",
      "Found 1908 images belonging to 2 classes.\n",
      "Found 1908 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory('/Users/faizahkureshi/Desktop/Capstone Project/DataSet 2/train', target_size=(224, 224), class_mode='binary', batch_size=64)\n",
    "# load and iterate validation dataset\n",
    "val = datagen.flow_from_directory('/Users/faizahkureshi/Desktop/Capstone Project/DataSet 2/val', target_size=(224, 224), class_mode='binary', batch_size=64)\n",
    "# load and iterate test dataset\n",
    "test = datagen.flow_from_directory('/Users/faizahkureshi/Desktop/Capstone Project/DataSet 2/test', target_size=(224, 224), class_mode='binary', batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Benign': 0, 'Malignant': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224,224,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43264</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,768,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43264\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m2,768,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,797,665</span> (10.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,797,665\u001b[0m (10.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,797,665</span> (10.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,797,665\u001b[0m (10.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = train.n//train.batch_size\n",
    "STEP_SIZE_VAL = val.n//val.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('/Users/faizahkureshi/Desktop/Capstone Project/training.log', separator=',', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 833ms/step - accuracy: 0.6557 - loss: 0.6635 - val_accuracy: 0.6708 - val_loss: 0.6322\n",
      "Epoch 2/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7031 - loss: 0.3051 - val_accuracy: 0.6346 - val_loss: 0.3271\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 13:54:46.501210: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-03-23 13:54:46.657993: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 766ms/step - accuracy: 0.6752 - loss: 0.6313 - val_accuracy: 0.6686 - val_loss: 0.6308\n",
      "Epoch 4/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6406 - loss: 0.3337 - val_accuracy: 0.7115 - val_loss: 0.3045\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 13:55:32.978196: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-03-23 13:55:33.123640: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 760ms/step - accuracy: 0.6694 - loss: 0.6225 - val_accuracy: 0.6692 - val_loss: 0.6180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, \n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data=test,\n",
    "                    validation_steps=STEP_SIZE_VAL,\n",
    "                    epochs=5,\n",
    "                    callbacks=[csv_logger]) \n",
    "model.save('/Users/faizahkureshi/Desktop/Capstone Project/first_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LRP***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "user_image_path = r'/Users/faizahkureshi/Desktop/Capstone Project/DataSet 2/train/Malignant/20586934 (17).png'\n",
    "img = Image.open(user_image_path)\n",
    "img = img.resize((224, 224))  # Resize to match the model's input size\n",
    "\n",
    "# Convert the image to RGB format if it's grayscale\n",
    "if img.mode != 'RGB':\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "img = np.array(img)  # Convert to NumPy array\n",
    "img = img / 255.0  # Normalize the image\n",
    "og_image=img\n",
    "#print(og_image.shape)\n",
    "    # Add batch dimension to the image\n",
    "img = np.expand_dims(img, axis=0)\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model,Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model=load_model(r\"/Users/faizahkureshi/Desktop/Capstone Project/first_model.h5\")\n",
    "last_conv_layer=model.get_layer('conv2d_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_layer(layer, g):\n",
    "    \"\"\"Clone a layer and pass its parameters through the function g.\"\"\"\n",
    "    layer = copy.deepcopy(layer)\n",
    "    try: layer.weight = torch.nn.Parameter(g(layer.weight))\n",
    "    except AttributeError: pass\n",
    "    try: layer.bias = torch.nn.Parameter(g(layer.bias))\n",
    "    except AttributeError: pass\n",
    "    return layer\n",
    "\n",
    "def dense_to_conv(layers):\n",
    "    \"\"\" Converts a dense layer to a conv layer \"\"\"\n",
    "    newlayers = []\n",
    "    for i,layer in enumerate(layers):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            newlayer = None\n",
    "            if i == 0:\n",
    "                m, n = 512, layer.weight.shape[0]\n",
    "                newlayer = nn.Conv2d(m,n,7)\n",
    "                newlayer.weight = nn.Parameter(layer.weight.reshape(n,m,7,7))\n",
    "            else:\n",
    "                m,n = layer.weight.shape[1],layer.weight.shape[0]\n",
    "                newlayer = nn.Conv2d(m,n,1)\n",
    "                newlayer.weight = nn.Parameter(layer.weight.reshape(n,m,1,1))\n",
    "            newlayer.bias = nn.Parameter(layer.bias)\n",
    "            newlayers += [newlayer]\n",
    "        else:\n",
    "            newlayers += [layer]\n",
    "    return newlayers\n",
    "\n",
    "def get_linear_layer_indices(model):\n",
    "    offset = len(model._modules['features']) + 1\n",
    "    indices = []\n",
    "    for i, layer in enumerate(model._modules['classifier']): \n",
    "        if isinstance(layer, nn.Linear): \n",
    "            indices.append(i)\n",
    "    indices = [offset + val for val in indices]\n",
    "    return indices\n",
    "\n",
    "def apply_lrp_on_model(model, image):\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    # Extract layers dynamically\n",
    "    layers = model.layers\n",
    "    if hasattr(model, 'classifier'):  # Check if the model has a classifier\n",
    "         linear_layer_indices =get_linear_layer_indices(model)\n",
    "    else:\n",
    "        linear_layer_indices = [i for i, layer in enumerate(layers) if isinstance(layer, torch.nn.Linear)]\n",
    "    \n",
    "    # Propagate image through layers and store activations\n",
    "    n_layers = len(layers)\n",
    "    activations = [image] + [None] * n_layers\n",
    "    \n",
    "    for layer in range(n_layers):\n",
    "        activation = layers[layer](activations[layer])\n",
    "        if isinstance(layers[layer], torch.nn.modules.pooling.AdaptiveAvgPool2d):\n",
    "            activation = torch.flatten(activation, start_dim=1)\n",
    "        activations[layer+1] = activation\n",
    "    \n",
    "    # Replace last layer with one-hot-encoding\n",
    "    output_activation = activations[-1].detach().cpu().numpy()\n",
    "    max_activation = output_activation.max()\n",
    "    one_hot_output = [val if val == max_activation else 0 for val in output_activation[0]]\n",
    "    activations[-1] = torch.FloatTensor([one_hot_output])\n",
    "    \n",
    "    # Backpropagate relevance scores\n",
    "    relevances = [None] * n_layers + [activations[-1]]\n",
    "    for layer in range(n_layers)[::-1]:\n",
    "        current = layers[layer]\n",
    "        if isinstance(current, torch.nn.MaxPool2d):\n",
    "            layers[layer] = torch.nn.AvgPool2d(2)\n",
    "            current = layers[layer]\n",
    "        if isinstance(current, (torch.nn.Conv2d, torch.nn.AvgPool2d, torch.nn.Linear)):\n",
    "            activations[layer] = activations[layer].data.requires_grad_(True)\n",
    "            \n",
    "            if layer <= linear_layer_indices[0]:\n",
    "                rho = lambda p: p + 0.25 * p.clamp(min=0)\n",
    "                incr = lambda z: z + 1e-9\n",
    "            elif linear_layer_indices[0] < layer <= linear_layer_indices[-1]:\n",
    "                rho = lambda p: p\n",
    "                incr = lambda z: z + 1e-9 + 0.25 * ((z**2).mean()**.5).data\n",
    "            else:\n",
    "                rho = lambda p: p\n",
    "                incr = lambda z: z + 1e-9\n",
    "            \n",
    "            z = incr(new_layer(layers[layer],rho).forward(activations[layer]))\n",
    "            #z = incr(new_layer(layers[layer], rho).forward(activations[layer]))\n",
    "            s = (relevances[layer+1] / z).data\n",
    "            (z * s).sum().backward()\n",
    "            c = activations[layer].grad\n",
    "            relevances[layer] = (activations[layer] * c).data\n",
    "        else:\n",
    "            relevances[layer] = relevances[layer+1]\n",
    "    \n",
    "    return relevances[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (1, 1, 224, 224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Apply transformations to the image\u001b[39;00m\n\u001b[1;32m      7\u001b[0m image_tensor \u001b[38;5;241m=\u001b[39m transform(img)\n\u001b[0;32m----> 8\u001b[0m image_relevances \u001b[38;5;241m=\u001b[39m \u001b[43mapply_lrp_on_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m image_relevances \u001b[38;5;241m=\u001b[39m image_relevances\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m image_relevances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minterp(image_relevances, (image_relevances\u001b[38;5;241m.\u001b[39mmin(),\n\u001b[1;32m     11\u001b[0m                                                 image_relevances\u001b[38;5;241m.\u001b[39mmax()), \n\u001b[1;32m     12\u001b[0m                                                 (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[0;32mIn[59], line 53\u001b[0m, in \u001b[0;36mapply_lrp_on_model\u001b[0;34m(model, image)\u001b[0m\n\u001b[1;32m     50\u001b[0m activations \u001b[38;5;241m=\u001b[39m [image] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m n_layers\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers):\n\u001b[0;32m---> 53\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layers[layer], torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpooling\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool2d):\n\u001b[1;32m     55\u001b[0m         activation \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(activation, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=119'>120</a>\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=120'>121</a>\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=121'>122</a>\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=122'>123</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=123'>124</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=124'>125</a>\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=221'>222</a>\u001b[0m     \u001b[39mfor\u001b[39;00m axis, value \u001b[39min\u001b[39;00m spec\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=222'>223</a>\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape[axis] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=223'>224</a>\u001b[0m             value,\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=224'>225</a>\u001b[0m             \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=225'>226</a>\u001b[0m         }:\n\u001b[0;32m--> <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=226'>227</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=227'>228</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=228'>229</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincompatible with the layer: expected axis \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=229'>230</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof input shape to have value \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=230'>231</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mbut received input with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=231'>232</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=232'>233</a>\u001b[0m             )\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=233'>234</a>\u001b[0m \u001b[39m# Check shape.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=234'>235</a>\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (1, 1, 224, 224)"
     ]
    }
   ],
   "source": [
    "image = '/Users/faizahkureshi/Desktop/Capstone Project/DataSet 2/test/Malignant/20586934 (10).png'\n",
    "img = Image.open(image)\n",
    "# Define transformations to apply to the image\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "# Apply transformations to the image\n",
    "image_tensor = transform(img)\n",
    "image_relevances = apply_lrp_on_model(model, image_tensor)\n",
    "image_relevances = image_relevances.permute(0,2,3,1).detach().cpu().numpy()[0]\n",
    "image_relevances = np.interp(image_relevances, (image_relevances.min(),\n",
    "                                                image_relevances.max()), \n",
    "                                                (0, 1))\n",
    "# Show relevances\n",
    "# pred_label = list(test.class_to_idx.keys())[\n",
    "#              list(test.class_to_idx.values())\n",
    "#             .index(labels[image_id])]\n",
    "def get_idx(pred):\n",
    "    threshold=0.5\n",
    "    return 1 if pred>threshold else 0\n",
    "\n",
    "result=get_idx(model.predict(image)[1])\n",
    "if result == 1:\n",
    "    print(\"Groundtruth for this image: \", result)\n",
    "\n",
    "    # Plot images next to each other\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image_relevances[:,:,0], cmap=\"seismic\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"This image is not classified correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NEW LRP***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "\n",
    "def new_layer(layer, g):\n",
    "    \"\"\"Clone a layer and pass its parameters through the function g.\"\"\"\n",
    "    layer = copy.deepcopy(layer)\n",
    "    try:\n",
    "        if hasattr(layer, 'weight'):\n",
    "            layer.weight = torch.nn.Parameter(g(layer.weight))\n",
    "        if hasattr(layer, 'bias'):\n",
    "            layer.bias = torch.nn.Parameter(g(layer.bias))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    return layer\n",
    "\n",
    "def apply_lrp_on_model(model, image):\n",
    "    # Add batch dimension to the image\n",
    "    image_tensor = torch.unsqueeze(image, 0)\n",
    "\n",
    "    # Extract layers dynamically\n",
    "    layers = model.layers if hasattr(model, 'layers') else list(model.children())\n",
    "    \n",
    "    # Assuming linear layers are at the end\n",
    "    linear_layer_indices = [i for i, layer in enumerate(layers) if isinstance(layer, torch.nn.Linear)]\n",
    "    \n",
    "    # Propagate image through layers and store activations\n",
    "    n_layers = len(layers)\n",
    "    activations = [image_tensor] + [None] * n_layers\n",
    "    \n",
    "    for layer in range(n_layers):\n",
    "        activation = layers[layer](activations[layer])\n",
    "        if isinstance(layers[layer], torch.nn.modules.pooling.AdaptiveAvgPool2d):\n",
    "            activation = torch.flatten(activation, start_dim=1)\n",
    "        activations[layer+1] = activation\n",
    "    \n",
    "    # Replace last layer with one-hot-encoding\n",
    "    output_activation = activations[-1].detach().cpu().numpy()\n",
    "    max_activation = output_activation.max()\n",
    "    one_hot_output = [val if val == max_activation else 0 for val in output_activation[0]]\n",
    "    activations[-1] = torch.FloatTensor([one_hot_output])\n",
    "    \n",
    "    # Backpropagate relevance scores\n",
    "    relevances = [None] * n_layers + [activations[-1]]\n",
    "    for layer in range(n_layers)[::-1]:\n",
    "        current = layers[layer]\n",
    "        if isinstance(current, torch.nn.MaxPool2d):\n",
    "            layers[layer] = torch.nn.AvgPool2d(2)\n",
    "            current = layers[layer]\n",
    "        if isinstance(current, (torch.nn.Conv2d, torch.nn.AvgPool2d, torch.nn.Linear)):\n",
    "            activations[layer] = activations[layer].data.requires_grad_(True)\n",
    "            \n",
    "            if layer <= linear_layer_indices[0]:\n",
    "                rho = lambda p: p + 0.25 * p.clamp(min=0)\n",
    "                incr = lambda z: z + 1e-9\n",
    "            elif linear_layer_indices[0] < layer <= linear_layer_indices[-1]:\n",
    "                rho = lambda p: p\n",
    "                incr = lambda z: z + 1e-9 + 0.25 * ((z**2).mean()**.5).data\n",
    "            else:\n",
    "                rho = lambda p: p\n",
    "                incr = lambda z: z + 1e-9\n",
    "            \n",
    "            z = incr(new_layer(layers[layer],rho).forward(activations[layer]))\n",
    "            s = (relevances[layer+1] / z).data\n",
    "            (z * s).sum().backward()\n",
    "            c = activations[layer].grad\n",
    "            relevances[layer] = (activations[layer] * c).data\n",
    "        else:\n",
    "            relevances[layer] = relevances[layer+1]\n",
    "    \n",
    "    return relevances[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to visualize the relevances\n",
    "def visualize_relevances(relevances, image):\n",
    "    # Normalize relevances\n",
    "    relevances = torch.abs(relevances).sum(dim=1, keepdim=True)\n",
    "    relevances /= relevances.max()\n",
    "\n",
    "    # Convert relevances to numpy array\n",
    "    relevances = relevances.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # Plot the original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.transpose(image.squeeze().detach().cpu().numpy(), (1, 2, 0)))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot the relevances\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(relevances, cmap='hot')\n",
    "    plt.title('Relevances')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the visualize_relevances function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d_9\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (1, 1, 224, 224, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m image_tensor \u001b[38;5;241m=\u001b[39m image_tensor\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Call the LRP function\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m relevances \u001b[38;5;241m=\u001b[39m \u001b[43mapply_lrp_on_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 31\u001b[0m, in \u001b[0;36mapply_lrp_on_model\u001b[0;34m(model, image)\u001b[0m\n\u001b[1;32m     28\u001b[0m activations \u001b[38;5;241m=\u001b[39m [image_tensor] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m n_layers\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers):\n\u001b[0;32m---> 31\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layers[layer], torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpooling\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool2d):\n\u001b[1;32m     33\u001b[0m         activation \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(activation, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=119'>120</a>\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=120'>121</a>\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=121'>122</a>\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=122'>123</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=123'>124</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py?line=124'>125</a>\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=221'>222</a>\u001b[0m     \u001b[39mfor\u001b[39;00m axis, value \u001b[39min\u001b[39;00m spec\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=222'>223</a>\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape[axis] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=223'>224</a>\u001b[0m             value,\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=224'>225</a>\u001b[0m             \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=225'>226</a>\u001b[0m         }:\n\u001b[0;32m--> <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=226'>227</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=227'>228</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=228'>229</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincompatible with the layer: expected axis \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=229'>230</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof input shape to have value \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=230'>231</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mbut received input with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=231'>232</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=232'>233</a>\u001b[0m             )\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=233'>234</a>\u001b[0m \u001b[39m# Check shape.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/faizahkureshi/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/src/layers/input_spec.py?line=234'>235</a>\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d_9\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (1, 1, 224, 224, 1)"
     ]
    }
   ],
   "source": [
    "image_path ='/Users/faizahkureshi/Desktop/Capstone Project/DataSet 2/test/Malignant/20586934 (10).png'\n",
    "\n",
    "img = Image.open(image_path)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image\n",
    "    transforms.ToTensor()            # Convert the image to a tensor\n",
    "])\n",
    "image_tensor = transform(img)\n",
    "\n",
    "image_tensor = torch.unsqueeze(image_tensor, 0)\n",
    "# Permute dimensions to (batch_size, height, width, channels)\n",
    "image_tensor = image_tensor.permute(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "relevances = apply_lrp_on_model(model, image_tensor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_relevances(relevances, image_tensor)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ecbe64a6d9bb256066cac82553e9f962664e0a1f17db54f216b083f10eb1666"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
